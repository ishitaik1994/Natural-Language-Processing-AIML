{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OudB5by50jlI"
   },
   "source": [
    "#DOMAIN: Digital content and entertainment industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rb0XOKbN_G4J"
   },
   "source": [
    "##CONTEXT\n",
    "The objective of this project is to build a text classification model that analyses the customer's\n",
    "sentiments based on their reviews in the IMDB database. The model uses a complex deep learning model to build\n",
    "an embedding layer followed by a classification algorithm to analyse the sentiment of the customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xT7MKZuMRaCg"
   },
   "source": [
    "##DATA DESCRIPTION:\n",
    "The Dataset of 50,000 movie reviews from IMDB, labelled by sentiment (positive/negative).\n",
    "Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For\n",
    "convenience, the words are indexed by their frequency in the dataset, meaning the for that has index 1 is the most\n",
    "frequent word. Use the first 20 words from each review to speed up training, using a max vocabulary size of\n",
    "10,000. As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m60jSbKJCYW9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY2DqwzH_TQI"
   },
   "source": [
    "##PROJECT OBJECTIVE:\n",
    "To Build a sequential NLP classifier which can use input text parameters to determine the\n",
    "customer sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q34-Y3nRKXdO"
   },
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxfwbrbuKbk2",
    "outputId": "86c26258-a416-4b3e-ef09-88ac52d997f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#### Add your code here ####\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Conv1D, GlobalMaxPool1D, LSTM, TimeDistributed, Flatten\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000, maxlen=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIKRRNDSXTP9",
    "outputId": "adfd24b0-27c8-4809-e406-60f05d66d54b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19051,)\n",
      "(19450,)\n",
      "[1 0 0 ... 0 1 0]\n",
      "[0 1 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNQRn9YbXg_X",
    "outputId": "a31ec884-e1ad-40a7-b24e-02a6a0fd624e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: \n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Summarize number of Labels\n",
    "print(\"Labels: \")\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0AGD3QvGD0Q",
    "outputId": "d7e1dc5f-9fbd-4281-fa7f-dd33cf320f32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of sequence in X_train: 299\n",
      "Max length of sequence in X_test:  299\n"
     ]
    }
   ],
   "source": [
    "X_train_max_len = max(len(x) for x in X_train)\n",
    "print(\"Max length of sequence in X_train: {}\".format(X_train_max_len))\n",
    "\n",
    "X_test_max_len = max(len(x) for x in X_test)\n",
    "print(\"Max length of sequence in X_test:  {}\".format(X_test_max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DldivBO4LTbP"
   },
   "source": [
    "### Padding each sentence to be of same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "E808XB4tLtic",
    "outputId": "055068cd-8a5f-438b-9021-f6461923dda3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length: \n",
      "Mean 159.68 words (60.730229)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize review length\n",
    "print(\"Review length: \")\n",
    "result = [len(x) for x in X_train]\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean(result), np.std(result)))\n",
    "# plot review length\n",
    "pyplot.boxplot(result)\n",
    "pyplot.show()\n",
    "\n",
    "# we can see that max reviews are under the 500 characters mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cLwVSYgaKBfz"
   },
   "outputs": [],
   "source": [
    "#padding to 300 length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_padded = pad_sequences(X_train, maxlen=300)\n",
    "X_test_padded = pad_sequences(X_test, maxlen=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBFFCrybMSXz"
   },
   "source": [
    "### Print shape of features & labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOcyRtZfMYZd"
   },
   "source": [
    "Number of review, number of words in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hdMCUPr7RaCm",
    "outputId": "7abe3ce3-d8aa-497b-8b9e-558e47bac57a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in x_train: 19051\n",
      "Number of reviews in x_test: 19450\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# summarize size\n",
    "# number of reviews\n",
    "print(\"Number of reviews in x_train: {}\".format(len(X_train)))\n",
    "print(\"Number of reviews in x_test: {}\".format(len(X_test)))\n",
    "#print(\"Padded Training and Test data: \")\n",
    "#print(len(X_train.shape))\n",
    "#print(len(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGVHeKOWyJiG",
    "outputId": "be07b72b-782d-4ac5-c23b-38420a2c376d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in each review is 300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# number of words in each review\n",
    "print(\"Number of words in each review is {0}\".format(X_train_padded[0].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cNk5sDvMr3j"
   },
   "source": [
    "Number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Z00-mYgMoKv",
    "outputId": "b7d15f65-a26a-4246-a3bc-cff5153f4cf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19051,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H7f5tPeaMxti",
    "outputId": "e81f74ed-6cd4-479f-b910-59c5e303b467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Labels: \n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test.shape\n",
    "print(\"Unique Labels: \")\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdXPWuOmNEbh"
   },
   "source": [
    "### Print value of any one feature and it's label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGLEdeFmNZfR"
   },
   "source": [
    "Feature value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKFyMa28zztL",
    "outputId": "33168fd9-87b5-4408-e0a3-f1604b5ee0d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the 100th review: [1, 14, 9, 6, 389, 20, 19, 6, 253, 1096, 65, 5, 4, 6891, 7, 1181, 3855, 5, 4, 620, 756, 7, 803, 674, 11, 113, 97, 14, 6, 55, 467, 2525, 20, 92, 387, 4, 2, 7, 4, 182, 2, 25, 39, 319, 14, 2065, 47, 389, 388, 5, 13, 594, 33, 4, 192, 15, 212, 9, 115, 2525, 88, 156, 40, 2065, 97, 170, 39, 486, 8, 622, 1801, 168, 6529, 776, 87, 20, 32, 187]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Value of the 100th review:\" ,X_train[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_85Hqm0Nb1I"
   },
   "source": [
    "Label value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FoehB5jNd1g",
    "outputId": "d07a9d7c-ff99-497b-8e20-67a9f7dd5a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Label: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Sentiment Label:\", y_train[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cof4LSxNxuv"
   },
   "source": [
    "### Decoding the feature value to get original sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_oiAyPZOkJD"
   },
   "source": [
    "First, retrieve a dictionary that contains mapping of words to their index in the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Clsk-yK8OtzD",
    "outputId": "e9114249-3cca-4af0-fd3e-eacf07074042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 1s 1us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imdb_wordindex = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRgOD5S2Uuvd"
   },
   "source": [
    "Now use the dictionary to get the original words from the encodings, for a particular sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJ504QDORwxj",
    "outputId": "82cf3492-e98a-4de6-c333-2af7b77673ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index_from = 3\n",
    "imdb_wordindex = {key:value + index_from for key, value in imdb_wordindex.items()}\n",
    "imdb_wordindex['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Jt1OWiT4Blr",
    "outputId": "8c80f854-549a-489a-9f54-2963e80cc463"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'wonderful',\n",
       " 'movie',\n",
       " 'with',\n",
       " 'a',\n",
       " 'fun',\n",
       " 'clever',\n",
       " 'story',\n",
       " 'and',\n",
       " 'the',\n",
       " 'dynamics',\n",
       " 'of',\n",
       " 'culture',\n",
       " 'differences',\n",
       " 'and',\n",
       " 'the',\n",
       " 'running',\n",
       " 'theme',\n",
       " 'of',\n",
       " \"what's\",\n",
       " 'important',\n",
       " 'in',\n",
       " 'life',\n",
       " 'make',\n",
       " 'this',\n",
       " 'a',\n",
       " 'very',\n",
       " 'under',\n",
       " 'appreciated',\n",
       " 'movie',\n",
       " \"don't\",\n",
       " 'let',\n",
       " 'the',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'you',\n",
       " 'from',\n",
       " 'seeing',\n",
       " 'this',\n",
       " 'keaton',\n",
       " 'has',\n",
       " 'wonderful',\n",
       " 'moments',\n",
       " 'and',\n",
       " 'i',\n",
       " 'wonder',\n",
       " 'at',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'comedy',\n",
       " 'is',\n",
       " 'never',\n",
       " 'appreciated',\n",
       " 'because',\n",
       " 'actors',\n",
       " 'like',\n",
       " 'keaton',\n",
       " 'make',\n",
       " 'going',\n",
       " 'from',\n",
       " 'humor',\n",
       " 'to',\n",
       " 'serious',\n",
       " 'bits',\n",
       " 'look',\n",
       " 'tremendously',\n",
       " 'easy',\n",
       " 'great',\n",
       " 'movie',\n",
       " 'all',\n",
       " 'around']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_word = {value: key for key, value in imdb_wordindex.items()}\n",
    "[inverted_word[index] for index in X_train[100] if index > index_from]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLGABrJoVZe6"
   },
   "source": [
    "Get the sentiment for the above sentence\n",
    "- positive (1)\n",
    "- negative (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XDyQGJT0Ve-a",
    "outputId": "ea59ac2e-ef5f-4452-d54b-7fe4fa083bac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train[100]\n",
    "# confirmed that the review is bad and the label also confirmed the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmCjr8miXIWB"
   },
   "source": [
    "### Define model\n",
    "- Defining a Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Np5GxT1caFEq"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vocabulary = 10000\n",
    "max_words = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary, 100, input_length=max_words))\n",
    "model.add(LSTM(100,return_sequences= True))\n",
    "dense_layer = Dense(100, activation='relu')\n",
    "model.add(TimeDistributed(dense_layer))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc4bknOobDby"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jw4RJ0CQbwFY"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sEzwazqbz3T"
   },
   "source": [
    "### Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Hx1yxwlb2Ue",
    "outputId": "6dd3dd32-5a7c-4cdf-97a2-1e6360a90b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 100)          1000000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 300, 100)          80400     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 300, 100)         10100     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30000)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 30001     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,120,501\n",
      "Trainable params: 1,120,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmkolKP4b-U6"
   },
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRg3KFXLcAkk",
    "outputId": "205284f0-81a7-48a1-d835-79a9ba946e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "298/298 [==============================] - 9s 31ms/step - loss: 0.0284 - accuracy: 0.9906\n",
      "Epoch 2/15\n",
      "298/298 [==============================] - 9s 30ms/step - loss: 0.0269 - accuracy: 0.9903\n",
      "Epoch 3/15\n",
      "298/298 [==============================] - 6s 22ms/step - loss: 0.0207 - accuracy: 0.9928\n",
      "Epoch 4/15\n",
      "298/298 [==============================] - 6s 20ms/step - loss: 0.0187 - accuracy: 0.9934\n",
      "Epoch 5/15\n",
      "298/298 [==============================] - 7s 22ms/step - loss: 0.0189 - accuracy: 0.9935\n",
      "Epoch 6/15\n",
      "298/298 [==============================] - 6s 20ms/step - loss: 0.0136 - accuracy: 0.9952\n",
      "Epoch 7/15\n",
      "298/298 [==============================] - 6s 21ms/step - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 8/15\n",
      "298/298 [==============================] - 5s 17ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 9/15\n",
      "298/298 [==============================] - 6s 20ms/step - loss: 0.0054 - accuracy: 0.9980\n",
      "Epoch 10/15\n",
      "298/298 [==============================] - 7s 23ms/step - loss: 0.0202 - accuracy: 0.9924\n",
      "Epoch 11/15\n",
      "298/298 [==============================] - 5s 18ms/step - loss: 0.0110 - accuracy: 0.9965\n",
      "Epoch 12/15\n",
      "298/298 [==============================] - 5s 17ms/step - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 13/15\n",
      "298/298 [==============================] - 6s 18ms/step - loss: 0.0086 - accuracy: 0.9970\n",
      "Epoch 14/15\n",
      "298/298 [==============================] - 6s 21ms/step - loss: 0.0080 - accuracy: 0.9972\n",
      "Epoch 15/15\n",
      "298/298 [==============================] - 5s 17ms/step - loss: 0.0139 - accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x78f7f582ad70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train_padded, y_train, epochs=15, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwLl54MXnkEA"
   },
   "source": [
    "### Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUqY-bD8RaDR",
    "outputId": "f5631420-e238-4b60-e0eb-7a2f5b3cc00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.1138\n",
      "Accuracy: 0.8640\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores, accuracy = model.evaluate(X_test_padded, y_test, verbose=0)\n",
    "print(\"Score: {:.4f}\".format(scores))\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2amr1tJn9Jz"
   },
   "source": [
    "### Predict on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Wl4idfWR_A8E"
   },
   "outputs": [],
   "source": [
    "#### Add your code here ####\n",
    "goodsample = \"i liked the movie\"\n",
    "badsample = \"the movies quality was poor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdbXlqq17W6a",
    "outputId": "77d3e1a2-1973-4932-a8e1-d8e8c098b5a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "Review: i liked the movie\n",
      "\tSentiment: positive\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Review: the movies quality was poor\n",
      "\tSentiment: negative\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for review in [goodsample, badsample]:\n",
    "    encoded_review = []\n",
    "    review_split = review.split(\" \")\n",
    "    for word in review_split:\n",
    "        encoded_review.append(imdb_wordindex[word])\n",
    "    review_padded = pad_sequences([encoded_review], maxlen=300)\n",
    "    pred = model.predict(review_padded)\n",
    "    if pred > 0.6:\n",
    "        sentiment = 'positive'\n",
    "    else:\n",
    "        sentiment = 'negative'\n",
    "    print(\"Review: {0}\\n\\tSentiment: {1}\".format(review, sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fU9Ahsw4CcS3"
   },
   "source": [
    "# part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBoUzpUqMpH8"
   },
   "source": [
    "#DOMAIN: Social media analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MffGWee7MucM"
   },
   "source": [
    "##CONTEXT:\n",
    "Past studies in Sarcasm Detection mostly make use of Twitter datasets collected using hashtag based\n",
    "supervision but such datasets are noisy in terms of labels and language. Furthermore, many tweets are replies to\n",
    "other tweets and detecting sarcasm in these requires the availability of contextual tweets.In this hands-on project,\n",
    "the goal is to build a model to detect whether a sentence is sarcastic or not, using Bidirectional LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbMfQUVyMzZg"
   },
   "source": [
    "##DATA DESCRIPTION:\n",
    "\n",
    "The dataset is collected from two news websites, theonion.com and huffingtonpost.com.\n",
    "This new dataset has the following advantages over the existing Twitter datasets:\n",
    "Since news headlines are written by professionals in a formal manner, there are no spelling mistakes and informal usage. This\n",
    "reduces the sparsity and also increases the chance of finding pre-trained embeddings.\n",
    "Furthermore, since the sole purpose of TheOnion is to publish sarcastic news, we get high-quality labels with much less noise as\n",
    "compared to Twitter datasets.\n",
    "Unlike tweets that reply to other tweets, the news headlines obtained are self-contained. This would help us in teasing apart the\n",
    "real sarcastic elements\n",
    "Content: Each record consists of three attributes:\n",
    "is_sarcastic: 1 if the record is sarcastic otherwise 0\n",
    "headline: the headline of the news article\n",
    "article_link: link to the original news article. Useful in collecting supplementary data\n",
    "Reference: https://github.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRR-nwxoM-ST"
   },
   "source": [
    "##PROJECT OBJECTIVE:\n",
    "Build a sequential NLP classifier which can use input text parameters to determine the\n",
    "customer sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jW2Uk8otQvi8",
    "outputId": "27df2f80-0ffc-4ae8-a4b9-9a82216c7563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Installing collected packages: typing-extensions, tensorflow-estimator, keras, tensorboard, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.3\n",
      "    Uninstalling tensorboard-2.12.3:\n",
      "      Successfully uninstalled tensorboard-2.12.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydantic 2.1.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.4.0 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 typing-extensions-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0O_n6OIEVyL",
    "outputId": "689a3b24-32bc-44da-b51a-977a6f13edb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0mgRpOvFMjKR"
   },
   "outputs": [],
   "source": [
    "#Set your project path\n",
    "project_path =  '/content/drive/My Drive/nlp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXYwajPeQbRq"
   },
   "source": [
    "##Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "StSLB-T8PuGr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data = pd.read_json(os.path.join(project_path,'Sarcasm_Headlines_Dataset.json'),lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "m6LXx4qHqgWN",
    "outputId": "2cefe5b6-88b1-4599-a480-48810a0629e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-4a34f4bc-e58c-481d-934c-26762aa95ab0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26704</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/american-...</td>\n",
       "      <td>american politics in moral free-fall</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/americas-...</td>\n",
       "      <td>america's best 20 hikes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/reparatio...</td>\n",
       "      <td>reparations and obama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26707</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/israeli-b...</td>\n",
       "      <td>israeli ban targeting boycott supporters raise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/gourmet-g...</td>\n",
       "      <td>gourmet gifts for the foodie 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26709 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a34f4bc-e58c-481d-934c-26762aa95ab0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-2210e95c-be3c-4a1e-ad7c-48d1b12156ae\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2210e95c-be3c-4a1e-ad7c-48d1b12156ae')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-2210e95c-be3c-4a1e-ad7c-48d1b12156ae button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4a34f4bc-e58c-481d-934c-26762aa95ab0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4a34f4bc-e58c-481d-934c-26762aa95ab0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                            article_link  \\\n",
       "0      https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1      https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2      https://local.theonion.com/mom-starting-to-fea...   \n",
       "3      https://politics.theonion.com/boehner-just-wan...   \n",
       "4      https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "...                                                  ...   \n",
       "26704  https://www.huffingtonpost.com/entry/american-...   \n",
       "26705  https://www.huffingtonpost.com/entry/americas-...   \n",
       "26706  https://www.huffingtonpost.com/entry/reparatio...   \n",
       "26707  https://www.huffingtonpost.com/entry/israeli-b...   \n",
       "26708  https://www.huffingtonpost.com/entry/gourmet-g...   \n",
       "\n",
       "                                                headline  is_sarcastic  \n",
       "0      former versace store clerk sues over secret 'b...             0  \n",
       "1      the 'roseanne' revival catches up to our thorn...             0  \n",
       "2      mom starting to fear son's web series closest ...             1  \n",
       "3      boehner just wants wife to listen, not come up...             1  \n",
       "4      j.k. rowling wishes snape happy birthday in th...             0  \n",
       "...                                                  ...           ...  \n",
       "26704               american politics in moral free-fall             0  \n",
       "26705                            america's best 20 hikes             0  \n",
       "26706                              reparations and obama             0  \n",
       "26707  israeli ban targeting boycott supporters raise...             0  \n",
       "26708                  gourmet gifts for the foodie 2014             0  \n",
       "\n",
       "[26709 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "wsNtC1fDqnH_",
    "outputId": "5a877a42-4e9b-4e94-dd24-387e5d8445a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26709, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-39cde8f6-a67c-48fb-857b-a7ec2c4efca0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26709.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.438953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39cde8f6-a67c-48fb-857b-a7ec2c4efca0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-61901e5b-d3b9-4d87-8cf8-074e6bf9ab0b\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-61901e5b-d3b9-4d87-8cf8-074e6bf9ab0b')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-61901e5b-d3b9-4d87-8cf8-074e6bf9ab0b button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-39cde8f6-a67c-48fb-857b-a7ec2c4efca0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-39cde8f6-a67c-48fb-857b-a7ec2c4efca0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "       is_sarcastic\n",
       "count  26709.000000\n",
       "mean       0.438953\n",
       "std        0.496269\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (data.shape)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "tNpztCllqwJT",
    "outputId": "bf6aa096-1bd9-494e-8e3a-815819310848"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"the 'roseanne' revival catches up to our thorny political mood, for better and worse\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['headline'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxLSk1n9rFL2",
    "outputId": "bf70cc87-0b7d-4bc2-98e2-84d14bce4541"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "##The column headline needs to be cleaned up as we have special characters and numbers in the column\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "def cleanData(text):\n",
    "  text = re.sub(r'\\d+', '', text)\n",
    "  text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "  return text\n",
    "\n",
    "data['headline']=data['headline'].apply(cleanData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "e_FfMsSr3W73",
    "outputId": "b417dd14-395c-4e4f-aba0-5cea99bc57eb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'the roseanne revival catches up to our thorny political mood for better and worse'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['headline'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6pXf7A78E2H"
   },
   "source": [
    "## Drop `article_link` from dataset.\n",
    "As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VLSVsvrlP9qD"
   },
   "outputs": [],
   "source": [
    "data.drop('article_link',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0h6IOxU8OdH"
   },
   "source": [
    "## Get the Length of each line and find the maximum length.\n",
    "As different lines are of different length. We need to pad the our sequences using the max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BRAsChZAQmr3"
   },
   "outputs": [],
   "source": [
    "maxlen = max([len(text) for text in data['headline']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35abKfRx8as3"
   },
   "source": [
    "## Import required modules required for model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DVel73hYEV4r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ziybaD1RdD9"
   },
   "source": [
    "# Set Different Parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jPw9gAN_EV6m"
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "maxlen = max([len(text) for text in data['headline']])\n",
    "embedding_size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9abSe-bM8fn9"
   },
   "source": [
    "## Apply Keras Tokenizer of headline column of your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "T9Ad26HfTFMS"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=' ', char_level=False)\n",
    "tokenizer.fit_on_texts(data['headline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ffi63KsST3P"
   },
   "source": [
    "##Define features and lbels for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnjxBdqmSS4s",
    "outputId": "30e1df95-8493-4063-abef-ab6d81849935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 26709\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0  287  780 3505 2213   47  353   92 2111    5\n",
      " 2476 8139]\n",
      "Number of Labels:  26709\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(data['headline'])\n",
    "X = pad_sequences(X, maxlen = maxlen)\n",
    "y = np.asarray(data['is_sarcastic'])\n",
    "\n",
    "print(\"Number of Samples:\", len(X))\n",
    "print(X[0])\n",
    "print(\"Number of Labels: \", len(y))\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJLyKg-98rH_"
   },
   "source": [
    "## Get the Vocabulary size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-2w0gHEUUIo",
    "outputId": "0814a9f0-4114-47bb-80d2-81709c53a2d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27667\n"
     ]
    }
   ],
   "source": [
    "num_words=len(tokenizer.word_index)\n",
    "print (num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hjeMi40XcB1"
   },
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUF1TuQa8ux0"
   },
   "source": [
    "##Get Glove Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "vq5AIfRtMeZh"
   },
   "outputs": [],
   "source": [
    "glove_file = project_path + \"glove.6B.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "DJLX_n2WMecA"
   },
   "outputs": [],
   "source": [
    "#Extract Glove embedding zip file\n",
    "from zipfile import ZipFile\n",
    "with ZipFile(glove_file, 'r') as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IuXlu8-U3HG"
   },
   "source": [
    "# Get the Word Embeddings using Embedding file from drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "elZ-T5aFGZmZ"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = './glove.6B.200d.txt'\n",
    "\n",
    "embeddings = {}\n",
    "for o in open(EMBEDDING_FILE):\n",
    "    word = o.split(\" \")[0]\n",
    "    # print(word)\n",
    "    embd = o.split(\" \")[1:]\n",
    "    embd = np.asarray(embd, dtype='float32')\n",
    "    # print(embd)\n",
    "    embeddings[word] = embd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTPxveDmVCrA"
   },
   "source": [
    "# Create a weight matrix for words in training docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "xQgOhiywU9nU",
    "outputId": "337986ac-8509-48ac-e892-d26a912354b7"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e5906334edd0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 27667 is out of bounds for axis 0 with size 27667"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((num_words, 200))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "len(embeddings.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7IbWuEX82Ra"
   },
   "source": [
    "##Create and Compile your Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "d7jhsSgYXG4l"
   },
   "outputs": [],
   "source": [
    "### Embedding layer for hint\n",
    "## model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n",
    "### Bidirectional LSTM layer for hint\n",
    "## model.add(Bidirectional(LSTM(128, return_sequences = True)))\n",
    "import tensorflow as tf\n",
    "\n",
    "input_layer = Input(shape=(maxlen,),dtype=tf.int64)\n",
    "embed = Embedding(embedding_matrix.shape[0],output_dim=200,weights=[embedding_matrix],input_length=maxlen, trainable=True)(input_layer)\n",
    "lstm=Bidirectional(LSTM(128))(embed)\n",
    "drop=Dropout(0.3)(lstm)\n",
    "dense =Dense(100,activation='relu')(drop)\n",
    "out=Dense(2,activation='softmax')(dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJFMxZwMWoTw"
   },
   "source": [
    "##Model Fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpVkajCcWnRK",
    "outputId": "cc4a0f47-adb6-468d-f69c-83801294828b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 240)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 240, 200)          5533400   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 256)               336896    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               25700     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5896198 (22.49 MB)\n",
      "Trainable params: 5896198 (22.49 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 5\n",
    "\n",
    "model = Model(input_layer,out)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TNDkfYCWte4Q",
    "outputId": "389ec8ac-4752-42c9-cbb3-a011ef3b15ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "214/214 [==============================] - 37s 114ms/step - loss: 0.4467 - accuracy: 0.7866\n",
      "Epoch 2/5\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 0.2651 - accuracy: 0.8918\n",
      "Epoch 3/5\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1813 - accuracy: 0.9286\n",
      "Epoch 4/5\n",
      "214/214 [==============================] - 8s 37ms/step - loss: 0.1161 - accuracy: 0.9570\n",
      "Epoch 5/5\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 0.0775 - accuracy: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x78efec729fc0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "model.fit(X_train,y_train,batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqvqFFu7tjqH",
    "outputId": "ee5d09da-42cb-4469-a820-6761fd97aff3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 3s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(np.array(X_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YkgjPw-ctohS"
   },
   "outputs": [],
   "source": [
    "test_pred = [1 if j>i else 0 for i,j in test_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZdOiXHd5N8cp"
   },
   "source": [
    "##Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "683aglhutqwx",
    "outputId": "3060c24d-b72f-4696-a356-550f59954b1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2712,  319],\n",
       "       [ 402, 1909]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNjr1BQBtxGe",
    "outputId": "300f9096-e9c2-4b00-f332-b480c09eb56f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      3031\n",
      "           1       0.86      0.83      0.84      2311\n",
      "\n",
      "    accuracy                           0.87      5342\n",
      "   macro avg       0.86      0.86      0.86      5342\n",
      "weighted avg       0.86      0.87      0.86      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssLxdHIGt6Nl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
